
-- Be explicit about the compression format to use
SET parquet.compression = SNAPPY;

-- Measures the time between search requests, marking a new session whenever an
-- identity has spent more than 1800 seconds between searches.
-- See https://www.dataiku.com/learn/guide/code/reshaping_data/sessionization.html
-- for more details
WITH sessionized AS (
    SELECT
        *,
        -- The first session in each day per identity is null, convert those into
        -- session 0 and everything else into session 1+
        -- Include ymd in session id so they are unique across days.
        CONCAT_WS('_', CAST(year AS string), CAST(month AS string), CAST(day AS string), identity, CAST(IF(session_num IS NULL, 0, session_num + 1) AS string)) AS session_id
    FROM (
        SELECT
            *,
            -- Sums the new session markers (each either 1 or 0) from the begining up to the current
            -- row, giving the number of new sessions that have occured prior to this row..
            SUM(CAST(new_session AS int)) OVER (PARTITION BY identity ORDER BY `timestamp`) AS session_num
        FROM (
            SELECT
                *,
                -- Records a 1 each time the time difference between current and previous search
                -- by this identity is larger than the session timeout.
                `timestamp` - LAG(`timestamp`) OVER (PARTITION BY identity ORDER BY `timestamp`) >= 1800 AS new_session
            FROM (
                SELECT
                    *,
                    COUNT(1) OVER (PARTITION BY identity) AS rows_by_identity,
                    COUNT(1) OVER (PARTITION BY ip) AS q_by_ip_day
                FROM
                    discovery.query_clicks_hourly
                WHERE
                    year = 2022
                    AND month = 1
                    AND day = 1
            ) x
            WHERE
                -- We have some identities that make hundreds of thousands of queries a day.
                -- The later sum(new_session) over (...) expression chokes on those identities,
                -- essentially summing each possible set of rows. We dont really need that data
                -- for ML purposes, so filter it early.
                rows_by_identity < 1000
        ) y
    ) z
)

INSERT OVERWRITE TABLE
    discovery.query_clicks_daily
PARTITION(
    year = 2022,
    month = 1,
    day = 1)
SELECT
    -- Order here must match the create_table statement
    sessionized.query,
    sessionized.q_by_ip_day,
    sessionized.`timestamp`,
    sessionized.wikiid,
    sessionized.project,
    sessionized.hits,
    sessionized.clicks,
    sessionized.session_id,
    sessionized.request_set_token
FROM
    sessionized
WHERE
    -- Filter down to searches with clicks
    sessionized.clicks IS NOT NULL
;